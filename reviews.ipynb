{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1960c22c-47b8-455c-87a9-63fda2935216",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "\n",
    "# %pip install -U sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "N_SPLIT = 10\n",
    "ROOT_PATH = '/Users/ruby0322/Projects/112-1/IRTM/term-project/irtm-final-project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886b51ba-6618-4c65-ac94-700ce3554f6c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def read_network(input_filepath) -> dict[list[str]]:\n",
    "    G = {}\n",
    "    with open(input_filepath) as file:\n",
    "        while (line := file.readline()):\n",
    "            if line:\n",
    "                n1, n2 = line.split()\n",
    "                if n1 in G:\n",
    "                    G[n1].append(n2)\n",
    "                else:\n",
    "                    G[n1] = [n2]\n",
    "                if n2 in G:\n",
    "                    G[n2].append(n1)\n",
    "                else:\n",
    "                    G[n2] = [n1]\n",
    "    return G\n",
    "\n",
    "def dijkstra_unweighted(G, start):\n",
    "    \"\"\"\n",
    "    Compute shortest paths from the start node to all other nodes in an unweighted graph.\n",
    "\n",
    "    :param G: A dictionary representing the adjacency list of the graph. \n",
    "                  Each key is a node, and its value is a list of its neighbors.\n",
    "    :param start: The starting node\n",
    "    :return: A dictionary of shortest distances from the start node to each other node.\n",
    "    \"\"\"\n",
    "    # Initialize distances as infinity and distance to start node as 0\n",
    "    distances = {node: float('infinity') for node in G}\n",
    "    distances[start] = 0\n",
    "\n",
    "    # Priority queue to hold nodes and their current distances\n",
    "    pq = [(0, start)]\n",
    "\n",
    "    while pq:\n",
    "        current_distance, current_node = heapq.heappop(pq)\n",
    "\n",
    "        # Explore neighbors\n",
    "        for neighbor in G[current_node]:\n",
    "            distance = current_distance + 1  # Each edge has a weight of 1\n",
    "\n",
    "            # Update distance if a shorter path is found\n",
    "            if distance < distances[neighbor]:\n",
    "                distances[neighbor] = distance\n",
    "                heapq.heappush(pq, (distance, neighbor))\n",
    "\n",
    "    return distances\n",
    "\n",
    "def get_subnetwork(G, mu, k=1):\n",
    "    distances = dijkstra_unweighted(G, mu)\n",
    "    return [list(filter(lambda node: distances[node] == dep, distances.keys())) for dep in range(k)]\n",
    "\n",
    "def split_reviews(input_filepath, output_folder) -> None:\n",
    "    with open(input_filepath) as file:\n",
    "        s = file.read()\n",
    "        s = s.split('\\n')\n",
    "        slen = len(s)\n",
    "        n_reviews = (slen // N_SPLIT) + 1\n",
    "        for i in range(N_SPLIT):\n",
    "            ending = slen if i == N_SPLIT - 1 else n_reviews*(i+1)\n",
    "            ss = s[n_reviews*i:ending]\n",
    "            print(f'[split-reviews] Parsing reviews split {i}...')\n",
    "            reviews = dict()\n",
    "            exec('\\n'.join(ss), { 'reviews': reviews })\n",
    "            print(reviews)\n",
    "            print(f'[split-reviews] Saving reviews split {i} into \"reviews-{i}.csv\"...')\n",
    "            pd.DataFrame(reviews).transpose().dropna().to_csv(f'{output_folder}/reviews-{i}.csv', index=False)            \n",
    "\n",
    "def iterate_over_split_reviews(func):\n",
    "    \"\"\"\n",
    "    func: a function that returns a list of boolean that indexes the reviews\n",
    "    \"\"\"\n",
    "    aggr = pd.DataFrame()\n",
    "    for i in range(N_SPLIT):\n",
    "        df = pd.read_csv(f'./reviews/reviews-{i}.csv')\n",
    "        df = df[func(df)]\n",
    "        aggr = pd.concat([aggr, df])\n",
    "    return aggr\n",
    "\n",
    "def get_network_reviews(network: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    network: list of users in the network\n",
    "    \"\"\"\n",
    "    def f(df: pd.DataFrame):\n",
    "        return df['user'].isin(network)\n",
    "    return iterate_over_split_reviews(f)\n",
    "\n",
    "def get_subnetwork_reviews_by_mu(G, mu, k=1):\n",
    "    network = get_subnetwork(G, mu, k)\n",
    "    aggr = pd.DataFrame()\n",
    "    for dep, subnetwork in enumerate(network):\n",
    "        df = get_network_reviews(subnetwork)\n",
    "        df['depth'] = [dep] * df.shape[0]\n",
    "        aggr = pd.concat([aggr, df])\n",
    "    return aggr\n",
    "\n",
    "def split_graph(mu, subgraph, time_threshold):\n",
    "\n",
    "    def user_time_threshold(mu, subgraph, threshold=0.8): # subgraph type = pd.Dataframe\n",
    "        user_time_list = sorted(list(subgraph[subgraph['user'] == mu]['unixtime']))\n",
    "        return user_time_list[int(len(user_time_list)*threshold)]\n",
    "    \n",
    "    def pre_post_split(mu, subgraph, time_threshold=0.8):\n",
    "        post = subgraph.loc[((subgraph['user'] == mu) &( subgraph['unixtime'] > user_time_threshold(mu, subgraph, time_threshold)))].copy(deep=True)\n",
    "        pre = subgraph.loc[~subgraph.index.isin(post.index)]\n",
    "        post.drop('unixtime', inplace=True, axis=1)\n",
    "        pre.drop('unixtime', inplace=True, axis=1)\n",
    "        return pre, post\n",
    "\n",
    "    pre, post = pre_post_split(mu, subgraph)\n",
    "    def pre_mu_split(mu, pre, post):\n",
    "        pre_mu = pre.loc[pre['user'] == mu]\n",
    "        pre_not_mu = pre.loc[~pre.index.isin(pre_mu.index)]\n",
    "\n",
    "        post = post[post['work'].isin(pre_not_mu['work'])]\n",
    "        pre_mu.drop('user', inplace=True, axis=1)\n",
    "        pre_not_mu.drop('user', inplace=True, axis=1)\n",
    "        post.drop('user', inplace=True, axis=1)\n",
    "        return pre_mu, pre_not_mu, post\n",
    "    \n",
    "    pre_mu, pre_not_mu, post = pre_mu_split(mu, pre, post)\n",
    "\n",
    "    ITEM_LIST = list(pre_not_mu['work'].unique())\n",
    "    ITEM_NUM = len(ITEM_LIST)\n",
    "    new_post = []\n",
    "\n",
    "    for i, work in enumerate(ITEM_LIST):\n",
    "        if(work in list(post['work'])):\n",
    "            new_post.append(list(post.loc[post['work'] == work].iloc[0].copy(deep=True)))\n",
    "        else:\n",
    "            new_post.append([])\n",
    "            new_post[i].append(work)\n",
    "            for j in range(len(post.columns) - 1):\n",
    "                new_post[i].append(0)\n",
    "    post = pd.DataFrame(np.array(new_post), columns=list(post.columns))\n",
    "\n",
    "    return pre_mu, pre_not_mu, post\n",
    "\n",
    "def get_pre_notmu_with_trust(pre_mu, pre_notmu):\n",
    "    def encode(x):\n",
    "      return model.encode(x, convert_to_tensor=True)\n",
    "\n",
    "    pre_mu['comment'] = pre_mu['comment'].apply(encode)\n",
    "    pre_notmu['comment'] = pre_notmu['comment'].apply(encode)\n",
    "\n",
    "    def f(cmt):\n",
    "      s = 0.\n",
    "      for mu_cmt in pre_mu['comment']:\n",
    "        s += float(util.pytorch_cos_sim(cmt, mu_cmt)[0][0])\n",
    "      return s\n",
    "\n",
    "    pre_notmu['trust'] = pre_notmu['comment'].apply(f)\n",
    "    pre_notmu['trust'] = pre_notmu['trust']/pre_mu.shape[0]\n",
    "\n",
    "    return pre_notmu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    os.chdir(ROOT_PATH)\n",
    "    # split_reviews('./raw-data/reviews.txt', 'reviews')\n",
    "    G = read_network(f'./raw-data/edges.txt')\n",
    "    # print(get_network_reviews(G['slash'] + ['slash']))\n",
    "    # print(pd.DataFrame(list(get_subnetwork(G, 'carterchristian1', 4).items())))\n",
    "    # print(get_subnetwork(G, 'slash', 2))\n",
    "    subgraph = get_subnetwork_reviews_by_mu(G, 'slash', 2)\n",
    "    pre_mu, pre_not_mu, post = split_graph('slash', subgraph, 0.8)\n",
    "    print(pre_mu)\n",
    "    print(pre_not_mu)\n",
    "    print(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
